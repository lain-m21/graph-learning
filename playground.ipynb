{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from subprocess import call\n",
    "from collections import deque\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from numba import jit\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import scipy\n",
    "from scipy import linalg, sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import average_precision_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = sparse.load_npz('./data/preprocessed/blogcatalog/adj_matrix.npz')\n",
    "adj_dict = pickle.load(open('./data/preprocessed/blogcatalog/adj_dict.pkl', 'rb'))\n",
    "node_labels = pickle.load(open('./data/preprocessed/blogcatalog/node_labels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(adj_matrix, dim=128):\n",
    "    n, m = adj_matrix.shape\n",
    "    diags = adj_matrix.sum(axis=1).flatten()\n",
    "    D = sparse.spdiags(diags, [0], m, n, format='csr')\n",
    "    L = D - adj_matrix\n",
    "    with scipy.errstate(divide='ignore'):\n",
    "        diags_sqrt = 1.0 / scipy.sqrt(diags)\n",
    "    diags_sqrt[scipy.isinf(diags_sqrt)] = 0\n",
    "    DH = sparse.spdiags(diags_sqrt, [0], m, n, format='csr')\n",
    "    laplacian = DH.dot(L.dot(DH))\n",
    "\n",
    "    _, v = sparse.linalg.eigs(laplacian, k=dim + 1, which='SM')\n",
    "    embedding = v[:, 1:].real\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = spectral_clustering(adj_matrix.astype(np.int16), dim=128)\n",
    "scaler = StandardScaler()\n",
    "embedding = scaler.fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2 = spectral_clustering(adj_matrix, dim=128)\n",
    "scaler = StandardScaler()\n",
    "embedding_2 = scaler.fit_transform(embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embedding, node_labels, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=12)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(), n_jobs=12)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27166209858445056"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_classification_kfold(embedding, node_labels, n_splits=5, random_state=21):\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    score_f1_kfold = []\n",
    "    score_ap_kfold = []\n",
    "    for i, (index_train, index_test) in tqdm(enumerate(kf.split(node_labels))):\n",
    "        X_train, X_test = embedding[index_train], embedding[index_test]\n",
    "        y_train, y_test = node_labels[index_train], node_labels[index_test]\n",
    "        \n",
    "        clf = OneVsRestClassifier(LogisticRegression(), n_jobs=21)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        preds_label = clf.predict(X_test)\n",
    "        preds_proba = clf.predict_proba(X_test)\n",
    "        \n",
    "        score_f1 = f1_score(y_test, preds_label, average='weighted')\n",
    "        score_ap = average_precision_score(y_test, preds_proba, average='weighted')\n",
    "        score_f1_kfold.append(score_f1)\n",
    "        score_ap_kfold.append(score_ap)\n",
    "        \n",
    "    return score_f1_kfold, score_ap_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "5it [00:09,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "score_f1, score_ap = node_classification_kfold(embeddings, node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.266720395265443"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35253627881128524"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010745377351144968"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(score_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01187607619124917"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(score_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit('i8[:](i8[:, :])')\n",
    "def get_edge_list(adj_matrix):\n",
    "    edge_list = []\n",
    "    start_nodes = np.arange(adj_matrix.shape[0])\n",
    "    for start in start_nodes:\n",
    "        end_nodes = np.nonzero(adj_matrix[start].toarray().reshape(-1, ))[0]\n",
    "        end_nodes = end_nodes[end_nodes > start]\n",
    "        for end in end_nodes:\n",
    "            edge_list.append((start, end))\n",
    "    \n",
    "    return np.array(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = get_edge_list(adj_matrix)\n",
    "nodes = list(range(adj_matrix.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit('i8[:, :](i8[:, :], f8)')\n",
    "def sample_negative_links(edge_list, neg_ratio=1.0):\n",
    "    nodes = np.unique(edge_list)\n",
    "    index_shuffle = np.random.permutation(np.arange(len(nodes)))\n",
    "    nodes = nodes[index_shuffle]\n",
    "    \n",
    "    neg_size = int(len(edge_list) * neg_ratio)\n",
    "    result = deque([])\n",
    "    for i, start in enumerate(nodes):\n",
    "        end_nodes = nodes[nodes > start]\n",
    "        drop_nodes = edge_list[edge_list[:, 0] == start][:, 1]\n",
    "        end_nodes = np.setdiff1d(end_nodes, drop_nodes)\n",
    "        for end in end_nodes:\n",
    "            edge = np.array([start, end], dtype=int)\n",
    "            result.append(edge)\n",
    "            if len(result) == neg_size:\n",
    "                break\n",
    "        if len(result) == neg_size:\n",
    "                break\n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit('Tuple((i8[:, :], i8[:, :]))(i8[:, :], f8)')\n",
    "def split_graph(edge_list, test_ratio=0.2):\n",
    "    node_degree = np.bincount(np.sort(edge_list.ravel()))\n",
    "    nodes = np.unique(edge_list)\n",
    "    split_train = deque([])\n",
    "    split_test = deque([])\n",
    "    for n in nodes:\n",
    "        edges = edge_list[edge_list[:, 0] == n]\n",
    "        num_split_test = int(node_degree[n] * test_ratio)\n",
    "        num_split_train = int(node_degree[n] * (1 - test_ratio))\n",
    "        if num_split_train <= 1:\n",
    "            split_test.append(edges)\n",
    "            split_train.append(edges)\n",
    "            continue\n",
    "            \n",
    "        candidates = deque([])\n",
    "        for edge in edges:\n",
    "            if node_degree[edge[1]] > 1:\n",
    "                candidates.append(edge)\n",
    "            else:\n",
    "                split_test.append(edge.reshape(1, 2))\n",
    "                split_train.append(edge.reshape(1, 2))\n",
    "        candidates = np.array(candidates)\n",
    "        if len(candidates) < 1:\n",
    "            continue\n",
    "        split_test_ends = np.random.choice(candidates[:, 1], num_split_test)\n",
    "        split_train_ends = np.setdiff1d(edges[:, 1], split_test_ends)\n",
    "        \n",
    "        split_test_edges = np.ones([len(split_test_ends), 2], dtype=int) * n\n",
    "        split_train_edges = np.ones([len(split_train_ends), 2], dtype=int) * n\n",
    "        \n",
    "        split_test_edges[:, 1] = split_test_ends\n",
    "        split_train_edges[:, 1] = split_train_ends\n",
    "        split_test.append(split_test_edges)\n",
    "        split_train.append(split_train_edges)\n",
    "        \n",
    "        for end in split_test_ends:\n",
    "            node_degree[end] -= 1\n",
    "    \n",
    "    return np.concatenate(split_train, axis=0), np.concatenate(split_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_train, edge_list_test = split_graph(edge_list, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244847, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108709, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340382"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_train.shape[0] + edge_list_test.shape[0] - 13174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333983, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2557430267333984\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "negative_links = sample_negative_links(edge_list_train, neg_ratio=1)\n",
    "print(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.839042901992798\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "embedding = spectral_clustering(adj_matrix, dim=128)\n",
    "print(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.931436538696289\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "embedding = spectral_clustering(adj_matrix_train, dim=128)\n",
    "print(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def edgelist_to_matrix(edge_list):\n",
    "    n = len(np.unique(edge_list))\n",
    "    adj_matrix = np.zeros([n, n], dtype=np.int16)\n",
    "    for edge in edge_list:\n",
    "        adj_matrix[edge[0], edge[1]] = 1\n",
    "        adj_matrix[edge[1], edge[0]] = 1\n",
    "    return sparse.csr_matrix(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix_train = edgelist_to_matrix(edge_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_links = sample_negative_links(edge_list_train, 1.0)\n",
    "edges_train = np.concatenate([edge_list_train, negative_links], axis=0)\n",
    "labels_train = np.concatenate([np.ones(len(edge_list_train), dtype=int), np.zeros(len(negative_links), dtype=int)])\n",
    "index_shuffle = np.random.permutation(np.arange(len(edges_train)))\n",
    "edges_train, labels_train = edges_train[index_shuffle], labels_train[index_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489694, 128)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = embedding[edges_train[:, 0], :] * embedding[edges_train[:, 1], :]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction(edge_list, mode='Hadamard', test_ratio=0.2, neg_ratio=1.0, n_trials=5, random_state=21):\n",
    "    np.random.seed(random_state)\n",
    "    scores_f1 = []\n",
    "    scores_ap = []\n",
    "    scores_auc = []\n",
    "    for i in range(n_trials):\n",
    "        print(f'Trial {i+1:d} / {n_trials:d}')\n",
    "        print('Split the graph into train and test.')\n",
    "        edge_list_train, edge_list_test = split_graph(edge_list, test_ratio)\n",
    "        adj_matrix_train = edgelist_to_matrix(edge_list_train)\n",
    "        \n",
    "        print('Compute node embeddings on the train graph split.')\n",
    "#         embedding = spectral_clustering(adj_matrix_train, dim=128)\n",
    "        model = Node2Vec(dim=128, walk_length=80, num_walks=10, context_size=10, epochs=1, return_param=1, inout_param=1)\n",
    "        embedding = model.learn_embedding(adj_matrix_train)\n",
    "        \n",
    "        print('Sample negative links for the train graph split.')\n",
    "        negative_links = sample_negative_links(edge_list_train, neg_ratio)\n",
    "        edges_train = np.concatenate([edge_list_train, negative_links], axis=0)\n",
    "        labels_train = np.concatenate([np.ones(len(edge_list_train), dtype=int), np.zeros(len(negative_links), dtype=int)])\n",
    "        index_shuffle = np.random.permutation(np.arange(len(edges_train)))\n",
    "        edges_train, labels_train = edges_train[index_shuffle], labels_train[index_shuffle]\n",
    "        \n",
    "        print('Sample negative links for the test graph split.')\n",
    "        negative_links = sample_negative_links(edge_list_test, neg_ratio)\n",
    "        edges_test = np.concatenate([edge_list_test, negative_links], axis=0)\n",
    "        labels_test = np.concatenate([np.ones(len(edge_list_test), dtype=int), np.zeros(len(negative_links), dtype=int)])\n",
    "        \n",
    "        if mode == 'Hadamard':\n",
    "            X_train = embedding[edges_train[:, 0], :] * embedding[edges_train[:, 1], :]\n",
    "            X_test = embedding[edges_test[:, 0], :] * embedding[edges_test[:, 1], :]\n",
    "        else:\n",
    "            X_train = embedding[edges_train[:, 0], :] + embedding[edges_train[:, 1], :]\n",
    "            X_test = embedding[edges_test[:, 0], :] + embedding[edges_test[:, 1], :]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        y_train, y_test = labels_train, labels_test\n",
    "        \n",
    "        print('Train a classifier.')\n",
    "        clf = LogisticRegression(solver='saga')\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print('Make link predictions.')\n",
    "        preds_label = clf.predict(X_test)\n",
    "        preds_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        score_f1 = f1_score(y_test, preds_label)\n",
    "        score_ap = average_precision_score(y_test, preds_proba)\n",
    "        score_auc = roc_auc_score(y_test, preds_proba)\n",
    "        \n",
    "        scores_f1.append(score_f1)\n",
    "        scores_ap.append(score_ap)\n",
    "        scores_auc.append(score_auc)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    return scores_f1, scores_ap, scores_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 / 5\n",
      "Split the graph into train and test.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-93cf2b806df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_ap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-15ebb5bd41bf>\u001b[0m in \u001b[0;36mlink_prediction\u001b[0;34m(edge_list, mode, test_ratio, neg_ratio, n_trials, random_state)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Trial {i+1:d} / {n_trials:d}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Split the graph into train and test.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0medge_list_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_list_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0madj_matrix_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medgelist_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m     \"\"\"\n\u001b[1;32m   2458\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0melements\u001b[0m \u001b[0mover\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores_f1, scores_ap, scores_auc = link_prediction(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071859961293571"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005836689585639017"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit('i8[:](i8[:, :])')\n",
    "def matrix_to_edgelist(adj_matrix):\n",
    "    edge_list = []\n",
    "    start_nodes = np.arange(adj_matrix.shape[0])\n",
    "    for start in start_nodes:\n",
    "        end_nodes = np.nonzero(adj_matrix[start].toarray().reshape(-1, ))[0]\n",
    "        end_nodes = end_nodes[end_nodes > start]\n",
    "        for end in end_nodes:\n",
    "            edge_list.append((start, end))\n",
    "\n",
    "    return np.array(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec:\n",
    "    def __init__(self, dim, walk_length=80, num_walks=10, context_size=10, epochs=1,\n",
    "                 return_param=1, inout_param=1, directed=False, weighted=False, verbose=True, bin_path='node2vec',\n",
    "                 graph_path='./data/tmp/tmp.graph', embed_path='./data/embeddings/node2vec.emb'):\n",
    "\n",
    "        self.dim = dim\n",
    "        self.walk_length = walk_length\n",
    "        self.num_walks = num_walks\n",
    "        self.context_size = context_size\n",
    "        self.epochs = epochs\n",
    "        self.return_param = return_param\n",
    "        self.inout_param = inout_param\n",
    "        self.directed = directed\n",
    "        self.weighted = weighted\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.bin_path = bin_path\n",
    "        self.graph_path = graph_path\n",
    "        self.embed_path = embed_path\n",
    "\n",
    "    def learn_embedding(self, adj_matrix):\n",
    "        args = [os.path.expanduser(self.bin_path)]\n",
    "\n",
    "        edge_list = matrix_to_edgelist(adj_matrix)\n",
    "        self.save_edgelist(edge_list, self.graph_path)\n",
    "\n",
    "        args.append(f\"-i:{self.graph_path}\")\n",
    "        args.append(f\"-o:{self.embed_path}\")\n",
    "        args.append(f\"-d:{self.dim:d}\")\n",
    "        args.append(f\"-l:{self.walk_length:d}\")\n",
    "        args.append(f\"-r:{self.num_walks:d}\")\n",
    "        args.append(f\"-k:{self.context_size:d}\")\n",
    "        args.append(f\"-e:{self.epochs:d}\")\n",
    "        args.append(f\"-p:{self.return_param:.6f}\")\n",
    "        args.append(f\"-q:{self.inout_param:.6f}\")\n",
    "        if self.directed:\n",
    "            args.append(\"-dr\")\n",
    "        if self.weighted:\n",
    "            args.append(\"-w\")\n",
    "        if self.verbose:\n",
    "            args.append(\"-v\")\n",
    "\n",
    "        try:\n",
    "            call(args)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            raise Exception('node2vec not found. Please compile snap, place node2vec in the path')\n",
    "        embeddings = self.load_embeddings()\n",
    "        return embeddings\n",
    "\n",
    "    def load_embeddings(self):\n",
    "        with open(self.embed_path, 'r') as f:\n",
    "            n, d = f.readline().strip().split()\n",
    "            X = np.zeros([int(n), int(d)], dtype=np.float32)\n",
    "            for line in f:\n",
    "                emb = line.strip().split()\n",
    "                emb_fl = [float(emb_i) for emb_i in emb[1:]]\n",
    "                X[int(emb[0]), :] = emb_fl\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def save_edgelist(edge_list, path):\n",
    "        lines = ''\n",
    "        for edge in edge_list:\n",
    "            lines += str(edge[0]) + ' ' + str(edge[1]) + '\\n'\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node2Vec(dim=128, walk_length=80, num_walks=10, context_size=10, epochs=3, return_param=1, inout_param=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.learn_embedding(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open('./data/embeddings/node2vec.emb', 'r') as f:\n",
    "    n, d = f.readline().strip().split()\n",
    "#     X = np.zeros([int(n), int(d)], dtype=np.float32)\n",
    "    for line in f:\n",
    "        i += 1\n",
    "        emb = line.strip().split()\n",
    "        emb_fl = [float(emb_i) for emb_i in emb[1:]]\n",
    "#         X[int(emb[0]), :] = emb_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0807006 ,  0.0971116 ,  0.0733267 , ..., -0.362133  ,\n",
       "         0.177519  ,  0.0287865 ],\n",
       "       [-0.150951  , -0.0541495 ,  0.0384471 , ..., -0.382873  ,\n",
       "         0.399381  , -0.219226  ],\n",
       "       [-0.0297509 , -0.119281  , -0.0182671 , ..., -0.204567  ,\n",
       "         0.0411328 , -0.109958  ],\n",
       "       ...,\n",
       "       [-0.010897  ,  0.0793153 ,  0.00592847, ...,  0.443282  ,\n",
       "        -0.0537316 , -0.0853873 ],\n",
       "       [-0.0492875 , -0.226037  , -0.229748  , ...,  0.256811  ,\n",
       "         0.237568  , -0.214519  ],\n",
       "       [ 0.117696  , -0.0646967 , -0.221989  , ...,  0.125293  ,\n",
       "         0.283742  , -0.10564   ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
